There are many ways to characterize objects, concurrency, and their relationships. This section
discusses several different perspectives — definitional, system-based, stylistic, and modeling-based —
that together help establish a conceptual basis for concurrent object-oriented programming. 

----
1.2.1 Concurrency
----

Like most computing terms, "concurrency" is tricky to pin down. Informally, a concurrent program is
one that does more than one thing at a time. For example, a web browser may be simultaneously
performing an HTTP GET request to get an HTML page, playing an audio clip, displaying the number
of bytes received of some image, and engaging in an advisory dialog with a user. However, this
simultaneity is sometimes an illusion. On some computer systems these different activities might
indeed be performed by different CPUs. But on other systems they are all performed by a single timeshared CPU 
that switches among different activities quickly enough that they appear to be
simultaneous, or at least nondeterministically interleaved, to human observers. 

A more precise, though not very interesting definition of concurrent programming can be phrased
operationally: A Java virtual machine and its underlying operating system (OS) provide mappings
from apparent simultaneity to physical parallelism (via multiple CPUs), or lack thereof, by allowing
independent activities to proceed in parallel when possible and desirable, and otherwise by timesharing. 
Concurrent programming consists of using programming constructs that are mapped in this
way. Concurrent programming in the Java programming language entails using Java programming 
language constructs to this effect, as opposed to system-level constructs that are used to create new
operating system processes. By convention, this notion is further restricted to constructs affecting a
single JVM, as opposed to distributed programming, for example using remote method invocation
(RMI), that involves multiple JVMs residing on multiple computer systems. 

Concurrency and the reasons for employing it are better captured by considering the nature of a few
common types of concurrent applications:

Web services. Most socket-based web services (for example, HTTP daemons, servlet engines, and
application servers) are multithreaded. Usually, the main motivation for supporting multiple
concurrent connections is to ensure that new incoming connections do not need to wait out completion
of others. This generally minimizes service latencies and improves availability. 

Number crunching. Many computation-intensive tasks can be parallelized, and thus execute more
quickly if multiple CPUs are present. Here the goal is to maximize throughput by exploiting
parallelism. 

I/O processing. Even on a nominally sequential computer, devices that perform reads and writes on
disks, wires, etc., operate independently of the CPU. Concurrent programs can use the time otherwise
wasted waiting for slow I/O, and can thus make more efficient use of a computer's resources. 

Simulation. Concurrent programs can simulate physical objects with independent autonomous
behaviors that are hard to capture in purely sequential programs. 

GUI-based applications. Even though most user interfaces are intentionally single-threaded, they
often establish or communicate with multithreaded services. Concurrency enables user controls to stay
responsive even during time-consuming actions. 

Component-based software. Large-granularity software components (for example those providing
design tools such as layout editors) may internally construct threads in order to assist in bookkeeping,
provide multimedia support, achieve greater autonomy, or improve performance. 

Mobile code. Frameworks such as the java.applet package execute downloaded code in
separate threads as one part of a set of policies that help to isolate, monitor, and control the effects of
unknown code. 

Embedded systems. Most programs running on small dedicated devices perform real-time control.
Multiple components each continuously react to external inputs from sensors or other devices, and
produce external outputs in a timely manner. As defined in The Java™ Language Specification, the
Java platform does not support hard real-time control in which system correctness depends on actions
being performed by certain deadlines. Particular run-time systems may provide the stronger
guarantees required in some safety-critical hard-real-time systems. But all JVM implementations
support soft real-time control, in which timeliness and performance are considered quality-of-service
issues rather than correctness issues (see § 1.3.3). This reflects portability goals that enable the JVM to
be implemented on modern opportunistic, multipurpose hardware and system software. 


----
1.2.2 Concurrent Execution Constructs 
----

Threads are only one of several constructs available for concurrently executing code. The idea of
generating a new activity can be mapped to any of several abstractions along a granularity continuum
reflecting trade-offs of autonomy versus overhead. Thread-based designs do not always provide the 
best solution to a given concurrency problem. Selection of one of the alternatives discussed below can
provide either more or less security, protection, fault-tolerance, and administrative control, with either
more or less associated overhead. Differences among these options (and their associated programming
support constructs) impact design strategies more than do any of the details surrounding each one. 


1.2.2.1 Computer systems
----

If you had a large supply of computer systems, you might map each logical unit of execution to a
different computer. Each computer system may be a uniprocessor, a multiprocessor, or even a cluster
of machines administered as a single unit and sharing a common operating system. This provides
unbounded autonomy and independence. Each system can be administered and controlled separately
from all the others. 

However, constructing, locating, reclaiming, and passing messages among such entities can be
expensive, opportunities for sharing local resources are eliminated, and solutions to problems
surrounding naming, security, fault-tolerance, recovery, and reachability are all relatively heavy in
comparison with those seen in concurrent programs. So this mapping choice is typically applied only
for those aspects of a system that intrinsically require a distributed solution. And even here, all but the
tiniest embedded computer devices host more than one process. 


1.2.2.2 Processes 
----

A process is an operating-system abstraction that allows one computer system to support many units
of execution. Each process typically represents a separate running program; for example, an executing
JVM. Like the notion of a "computer system", a "process" is a logical abstraction, not a physical one.
So, for example, bindings from processes to CPUs may vary dynamically. 

Operating systems guarantee some degree of independence, lack of interference, and security among
concurrently executing processes. Processes are generally not allowed to access one another's storage
locations (although there are usually some exceptions), and must instead communicate via
interprocess communication facilities such as pipes. Most systems make at least best-effort promises
about how processes will be created and scheduled. This nearly always entails pre-emptive timeslicing — suspending 
processes on a periodic basis to give other processes a chance to run. 

The overhead for creating, managing, and communicating among processes can be a lot lower than in
per-machine solutions. However, since processes share underlying computational resources (CPUs,
memory, IO channels, and so on), they are less autonomous. For example, a machine crash caused by
one process kills all processes. 


1.2.2.3 Threads
----

Thread constructs of various forms make further trade-offs in autonomy, in part for the sake of lower
overhead. The main trade-offs are: 

Sharing. Threads may share access to the memory, open files, and other resources associated with a
single process. Threads in the Java programming language may share all such resources. Some
operating systems also support intermediate constructions, for example "lightweight processes" and
"kernel threads" that share only some resources, do so only upon explicit request, or impose other
restrictions. 

Scheduling. Independence guarantees may be weakened to support cheaper scheduling policies. At
one extreme, all threads can be treated together as a single-threaded process, in which case they may
cooperatively contend with each other so that only one thread is running at a time, without giving any
other thread a chance to run until it blocks (see § 1.3.2). At the other extreme, the underlying
scheduler can allow all threads in a system to contend directly with each other via pre-emptive
scheduling rules. Threads in the Java programming language may be scheduled using any policy lying
at or anywhere between these extremes. 

Communication. Systems interact via communication across wires or wireless channels, for example
using sockets. Processes may also communicate in this fashion, but may also use lighter mechanisms
such as pipes and interprocess signalling facilities. Threads can use all of these options, plus other
cheaper strategies relying on access to memory locations accessible across multiple threads, and
employing memory-based synchronization facilities such as locks and waiting and notification
mechanisms. These constructs support more efficient communication, but sometimes incur the
expense of greater complexity and consequently greater potential for programming error. 


1.2.2.4 Tasks and lightweight executable frameworks 
----

The trade-offs made in supporting threads cover a wide range of applications, but are not always
perfectly matched to the needs of a given activity. While performance details differ across platforms,
the overhead in creating a thread is still significantly greater than the cheapest (but least independent)
way to invoke a block of code — calling it directly in the current thread. 

When thread creation and management overhead become performance concerns, you may be able to
make additional trade-offs in autonomy by creating your own lighter-weight execution frameworks
that impose further restrictions on usage (for example by forbidding use of certain forms of blocking),
or make fewer scheduling guarantees, or restrict synchronization and communication to a more
limited set of choices. As discussed in § 4.1.4, these tasks can then be mapped to threads in about the
same way that threads are mapped to processes and computer systems. 

The most familiar lightweight executable frameworks are event-based systems and subsystems (see §
1.2.3, § 3.6.4, and § 4.1), in which calls triggering conceptually asynchronous activities are
maintained as events that may be queued and processed by background threads. Several additional
lightweight executable frameworks are described in Chapter 4. When they apply, construction and use
of such frameworks can improve both the structure and performance of concurrent programs. Their
use reduces concerns (see § 1.3.3) that can otherwise inhibit the use of concurrent execution
techniques for expressing logically asynchronous activities and logically autonomous objects (see §
1.2.4). 


----
1.2.3 Concurrency and OO Programming 
----

Objects and concurrency have been linked since the earliest days of each. The first concurrent OO
programming language (created circa 1966), Simula, was also the first OO language, and was among
the first concurrent languages. Simula's initial OO and concurrency constructs were somewhat
primitive and awkward. For example, concurrency was based around coroutines — thread-like
constructs requiring that programmers explicitly hand off control from one task to another. Several
other languages providing both concurrency and OO constructs followed — indeed, even some of the
earliest prototype versions of C++ included a few concurrency-support library classes. And Ada
(although, in its first versions, scarcely an OO language) helped bring concurrent programming out
from the world of specialized, low-level languages and systems. 






